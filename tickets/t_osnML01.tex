\subsection{OSN 23 Ансамбли в машинном обучении: комитеты, бэггинг, бустинг, стекинг. Алгоритм градиентного бустинга и его параметры.}
	\textbf{Ансамбли в машинном обучении} --- построение модели прогнозирования
		путем объединения сильных сторон набора более простых базовых моделей. [636]

	\textbf{Коммитеты} ---  это ансамбли, которые объединяют несколько решающих деревьев в одну модель.
		Каждое дерево обучается на случайной подвыборке данных и используется для прогнозирования с перекрестной проверкой. [chat GPT]

	\textbf{Комитетные методы} (committee methods) берут простое невзвешенное математическое ожидание прогнозов от каждой модели,
		по существу присваивая каждой модели одинаковую вероятность. [313]


	\textbf{Бутстрэп} --- универсальный инструмент для оценки статистической точности. [274]

	\textbf{Бэггинг} (bootstrap aggregating) --- использование бутстрэпа для улучшения самой оценки или прогноза. [306]

	% 17  \mathLe ->\mathLet
	\faEye \ задачу регрессии \mathLet мы аппроксимируем модель по обучающим данным $Z = \{(x{_1}, y{_1}),(x{_2}, y{_2}),
		\dots (X{_N}, y{_N})\}$, получая прогноз $\hat{f}(x)$ на входном значении $x$.
	Бэггинг, усредняет этот прогноз по коллекции бутсрэп-выборок, тем самым уменьшая ее дисперсию.
	Для каждой бутсрэп-выборки $Z^{*b}, b = 1, 2, \dots B$, мы аппрокисмируем нашу модель, получая прогноз $\hat{f}^{*b}(x)$. Бэггинг оценка определяется следующим образом:
\begin{equation}
    {\hat{f}_{bag} = \frac{1}{B}\sum_{b=1}^{B} \hat{f}^{*b}(x) } \label{eq:bagging}
\end{equation}
Обозначим через $\hat{\mathcal{P}}$ эмпирическое распределение, приписывающее равную вероятность $1/N$ каждой из точек $(x_i,y_i)$. На самом деле истинная бэггинг-оценка определяется как $E_{\hat{\mathcal{P}}}\hat{f}^{*}(x)$, где $Z^*=\{(x_1^*, y_1^*), (x_2^*, y_2^*), \dots, (x_N^*, y_N^*)\}$ и для каждой пары выполняется условие $(x_i^*, y_i^*) \sim \mathcal{P} $. \autoref{eq:bagging} представляет собой оценку Монте-Карло истинной бэггинг-оценки, стремясь к ней при $B \to \infty$.[308]


\textbf{Бустинг} был первоначально разработан для задач классификации, но его можно распространить и на регрессию.


Цель \textbf{бустинга} - создание процедуры, которая объединяет результаты многих слабых классификаторов для создания мощного комитета. С этой точки зрения бустинг имеет сходство с бэггингом и другими подходами, основанными на комитетах (см. раздел 8.8). Однако мы увидим, что эта связь в лучшем случае поверхностна и что бустинг в корне отличается от баггинга. [363]


Самый популярный алгоритм бустинга --- AdaBoost.M1.

\textbf{Стекинг} позволяет решить проблему уравновешивания
модели с учетом их сложности. 
$\mathLet \hat{f}_m^{-i}(x)$ --- прогноз в точке $x$ с использованием модели m, примененной к множеству данных с исключеным i-m обучающим наблюдением. Стековая оценка весов получается с помощью линейной регрессии $y_i$ на $\hat{f}_m^{-i}(x), m = 1, 2, \dots, M$ по методу наименьших квадратов. Стековые веса задаются формулами 
\begin{equation}
    \hat{w}^{st} = \operatorname*{arg\,min}_{w}\sum_{i=1}^N\biggl[y_i-\sum_{m=1}^Mw_m\hat{f}_m^{-i}(x_i)\biggr]^2\label{eq:stacking}
\end{equation}
Окончательный прогноз равен $\sum_m\hat{w}_m^{st}\hat{f}_m(x)$. Используя прогнозы $\hat{f}_m^{-i}(x)$, полученные с помощью перекрестной проверки, стекинг позволяет избежать придания неоправданно высокого веса моделям с более высокой сложностью. Лучшие результаты можно получить, потребовав, чтобы веса были неотрицательными, а их сумма равнялась единице.

Существует тесная связь между стекингом и выбором модели с помощью поэлементной перекрестной проверки. Если мы ограничим минимизацию \ref{eq:stacking} весовыми векторами w, которые содержат одну еденицу, а остальные элементы равны нулю, то это приведет к выбору модели $\hat{m}$ с наименьшей ошибкой поэлементной перекрестной проверки. Вместо того чтобы выбирать одну модель, стекинг комбинирует выбор модели с оценкой оптимального веса. Это часто приводит к лучшему прогнозированию, но меньшей интерпретируемости, чем выбор только одной из M моделей. [315]


Алгоритм \ref{alg:grad_boosting}[387] педставляет собой общий алгоритм градиентного бустинга деревьев для регрессии. Конкретные алгоритмы получаются путем вставки различных функций потерь $L(y, f(x))$.
Первая с


%	\begin{algorithm}[H]
%		\label{alg:grad_boosting}
%		\caption{Градиентный Бустинг Деревьев}
%		\begin{algorithmic}[1]
			\begin{enumerate}
				\item Инициализируем прогнозов: $f_0(x) = \underset{\gamma}{\mathrm{argmin}} \sum_{i=1}^{N} L(y_i, \gamma)$
				\item Для $m=1$ до M:
				\begin{enumerate}
					\item Вычисление остатков: $r_{im} = -\biggl[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\biggr]_{f=f_{m-1}}, \quad i=1,...,N$
					\item Аппроксимируем дерево регрессии по целям $r_{im}$ при заданных терминальных областях $R_{jm}, j = 1,2,\dots, J_m$
					\item Для $j = 1, 2, \dots, J_m$ вычисляем
							$\gamma_{im} = \underset{\gamma}{\mathrm{argmin}} \sum_{x_ \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma ))$
					\item Обновление прогнозов: $f_m(x) = f_{m-1}(x) + \sum_{j=1}^m\gamma_{jm} I(x \in R_{jm})$
				\end{enumerate}
				\item Выводим $\hat{f}_m(x) = f_M(x)$
			\end{enumerate} 
%		\end{algorithmic}
%	\end{algorithm}
	

[\cite[page 636-???]{ML_Robert}]